{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_columns=dict_keys(['target', 'dataset_path', 'dataset_name', 'dataset_split', 'num_of_examples', 'drafter', 'temperature', 'example_id', 'new_toks', 'ttft_ms', 'tpot_ms', 'out_toks_per_sec'])\n",
      "8=1*1*4*2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([], dtype='int64', name='example_id')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from hf_bench.summarize_results import list_tracked_files, get_columns\n",
    "\n",
    "\n",
    "filepaths = list_tracked_files(\"benchmark_results\")\n",
    "expected_columns = get_columns()\n",
    "print(f\"{expected_columns=}\")\n",
    "benign_missing_example_ids_compared_to_others = [] # Some (target, dataset_path, drafter, temperature) have less unique example IDs than others\n",
    "benign_missing_example_ids_compared_to_declared = [] # Some (target, dataset_path, drafter, temperature) have less unique example IDs than declared in the num_of_examples column\n",
    "catastrophic_missing_example_ids_compared_to_others = [] # Some (target, dataset_path, drafter, temperature, example_id) include less rows than excepted, where the expected number of rows is the Cartesian product of the number of unique (target, dataset_path, drafter, temperature)\n",
    "# for f in filepaths:\n",
    "f = \"benchmark_results/2025-02-04_01-05-29_4c55336/deepseek-ai-DeepSeek-R1-Distill-Llama-70B_openai-openai_humaneval_openai_humaneval_test_30_deepseek-ai-DeepSeek-R1-Distill-Llama-8B-codellama-CodeLlama-7b-Instruct-hf-bigcode-tiny_starcoder_py.csv\"\n",
    "df = pd.read_csv(f)\n",
    "col_counter = Counter(df.columns)\n",
    "for col in expected_columns:\n",
    "    assert col_counter[col] == 1, f\"Column {col} is missing in the dataframe or appears multiple times.\\nFilepath: {f}\"\n",
    "# Check that all example IDs appear the same number of times\n",
    "columns_for_index = [\"target\", \"dataset_path\", \"drafter\", \"temperature\"]\n",
    "df_example_ids_nunique = df.groupby(columns_for_index)[\"example_id\"].nunique()\n",
    "if df_example_ids_nunique.min() != df_example_ids_nunique.max():\n",
    "    print(f\"File {f} has missing example IDs (example IDs do not appear the same number of times).\")\n",
    "    benign_missing_example_ids_compared_to_others.append(f)\n",
    "# Check that all example IDs appear num_of_examples times\n",
    "expected_count = df[\"num_of_examples\"].max()\n",
    "if df_example_ids_nunique.min() != expected_count:\n",
    "    print(f\"File {f} has wrong number of example IDs (example IDs do not appear the same number of times).\")\n",
    "    benign_missing_example_ids_compared_to_declared.append(f)\n",
    "# Calculate the expected number of times each example ID should appear\n",
    "# This is the Cartesian product of the number of unique (target, dataset_path, drafter, temperature)\n",
    "df[\"drafter\"] = df[\"drafter\"].fillna(\"No Drafter (Autoregressive)\")\n",
    "expected_num_of_rows_per_example_id: int = df[\"target\"].nunique() * df[\"dataset_path\"].nunique() * df[\"drafter\"].nunique() * df[\"temperature\"].nunique()\n",
    "print(f\"{expected_num_of_rows_per_example_id}={df['target'].nunique()}*{df['dataset_path'].nunique()}*{df['drafter'].nunique()}*{df['temperature'].nunique()}\")\n",
    "# When grouping by (target, dataset_path, drafter, temperature, example_id), the number of rows should be the expected number of rows per example ID\n",
    "df_example_ids_count = df[columns_for_index + [\"example_id\"]].groupby(\"example_id\").count().min(axis=1)\n",
    "# all the incides for which the value is less than expected_num_of_rows_per_example_id\n",
    "mask = df_example_ids_count < expected_num_of_rows_per_example_id\n",
    "catastrophic_missing_example_ids = df_example_ids_count[mask].index.get_level_values(\"example_id\")\n",
    "catastrophic_missing_example_ids\n",
    "# if df_example_ids_count.min() != expected_num_of_rows_per_example_id:\n",
    "#     # Find the example IDs for which (target, dataset_path, drafter, temperature) have less rows than expected\n",
    "#     mask = df_example_ids_count < expected_num_of_rows_per_example_id\n",
    "#     catastrophic_missing_example_ids = df_example_ids_count[mask].index.get_level_values(\"example_id\")\n",
    "#     print(f\"File {f} has catastrophic missing example IDs. The following example IDs do not repeat the expected number of times, which is {expected_num_of_rows_per_example_id}={df['target'].nunique()}*{df['dataset_path'].nunique()}*{df['drafter'].nunique()}*{df['temperature'].nunique()}:\\n{catastrophic_missing_example_ids.to_list()}\")\n",
    "#     catastrophic_missing_example_ids_compared_to_others.append(f)\n",
    "# if benign_missing_example_ids_compared_to_others:\n",
    "#     warnings.warn(\"Some example IDs do not appear the same number of times in the following files:\\n\" + \"\\n\".join(benign_missing_example_ids_compared_to_others))\n",
    "# if benign_missing_example_ids_compared_to_declared:\n",
    "#     warnings.warn(\"Some example IDs appear only %d times in the dataframe although they should appear %d times according to the num_of_examples column.\\nFilepath: %s\" % (df_example_ids_nunique.min(), expected_count, f))\n",
    "# assert len(catastrophic_missing_example_ids_compared_to_others) == 0, f\"Some example IDs do not appear the same number of times in the following files:\\n\" + \"\\n\".join(catastrophic_missing_example_ids_compared_to_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[[\"new_toks\", \"ttft_ms\", \"tpot_ms\", \"out_toks_per_sec\"]] > 0).all().all().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating all the results CSVs into one dataframe...\n",
      "Found 49 tracked files in benchmark_results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting the number of unique example IDs for each experiment...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>example_id_nunique</th>\n",
       "      <th>new_toks</th>\n",
       "      <th>ttft_ms</th>\n",
       "      <th>tpot_ms</th>\n",
       "      <th>out_toks_per_sec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th>dataset_path</th>\n",
       "      <th>drafter</th>\n",
       "      <th>temperature</th>\n",
       "      <th>submission_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">deepseek-ai/DeepSeek-R1-Distill-Llama-70B</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">openai/openai_humaneval</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">No Drafter (Autoregressive)</th>\n",
       "      <th>0</th>\n",
       "      <th>2025-02-04_01-05-29_4c55336</th>\n",
       "      <td>30</td>\n",
       "      <td>512.0</td>\n",
       "      <td>297.1</td>\n",
       "      <td>122.6</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2025-02-04_01-05-29_4c55336</th>\n",
       "      <td>30</td>\n",
       "      <td>512.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>123.5</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">bigcode/tiny_starcoder_py</th>\n",
       "      <th>0</th>\n",
       "      <th>2025-02-04_01-05-29_4c55336</th>\n",
       "      <td>30</td>\n",
       "      <td>512.0</td>\n",
       "      <td>265.9</td>\n",
       "      <td>84.6</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2025-02-04_01-05-29_4c55336</th>\n",
       "      <td>30</td>\n",
       "      <td>512.0</td>\n",
       "      <td>258.7</td>\n",
       "      <td>85.5</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>codellama/CodeLlama-7b-Instruct-hf</th>\n",
       "      <th>0</th>\n",
       "      <th>2025-02-04_01-05-29_4c55336</th>\n",
       "      <td>30</td>\n",
       "      <td>512.0</td>\n",
       "      <td>428.7</td>\n",
       "      <td>101.5</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">mistralai/Mixtral-8x22B-Instruct-v0.1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">tau/scrolls</th>\n",
       "      <th>No Drafter (Autoregressive)</th>\n",
       "      <th>1</th>\n",
       "      <th>2025-02-06_21-32-25_ab73cc7</th>\n",
       "      <td>30</td>\n",
       "      <td>237.2</td>\n",
       "      <td>1325.3</td>\n",
       "      <td>168.0</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Qwen/Qwen2.5-0.5B-Instruct</th>\n",
       "      <th>0</th>\n",
       "      <th>2025-02-06_21-32-25_ab73cc7</th>\n",
       "      <td>30</td>\n",
       "      <td>188.3</td>\n",
       "      <td>1395.3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2025-02-06_21-32-25_ab73cc7</th>\n",
       "      <td>30</td>\n",
       "      <td>216.9</td>\n",
       "      <td>1365.3</td>\n",
       "      <td>98.5</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">double7/vicuna-68m</th>\n",
       "      <th>0</th>\n",
       "      <th>2025-02-06_21-32-25_ab73cc7</th>\n",
       "      <td>30</td>\n",
       "      <td>191.6</td>\n",
       "      <td>1336.1</td>\n",
       "      <td>130.2</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2025-02-06_21-32-25_ab73cc7</th>\n",
       "      <td>30</td>\n",
       "      <td>234.6</td>\n",
       "      <td>1322.4</td>\n",
       "      <td>136.4</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                              example_id_nunique  \\\n",
       "target                                    dataset_path            drafter                            temperature submission_id                                     \n",
       "deepseek-ai/DeepSeek-R1-Distill-Llama-70B openai/openai_humaneval No Drafter (Autoregressive)        0           2025-02-04_01-05-29_4c55336                  30   \n",
       "                                                                                                     1           2025-02-04_01-05-29_4c55336                  30   \n",
       "                                                                  bigcode/tiny_starcoder_py          0           2025-02-04_01-05-29_4c55336                  30   \n",
       "                                                                                                     1           2025-02-04_01-05-29_4c55336                  30   \n",
       "                                                                  codellama/CodeLlama-7b-Instruct-hf 0           2025-02-04_01-05-29_4c55336                  30   \n",
       "...                                                                                                                                                          ...   \n",
       "mistralai/Mixtral-8x22B-Instruct-v0.1     tau/scrolls             No Drafter (Autoregressive)        1           2025-02-06_21-32-25_ab73cc7                  30   \n",
       "                                                                  Qwen/Qwen2.5-0.5B-Instruct         0           2025-02-06_21-32-25_ab73cc7                  30   \n",
       "                                                                                                     1           2025-02-06_21-32-25_ab73cc7                  30   \n",
       "                                                                  double7/vicuna-68m                 0           2025-02-06_21-32-25_ab73cc7                  30   \n",
       "                                                                                                     1           2025-02-06_21-32-25_ab73cc7                  30   \n",
       "\n",
       "                                                                                                                                              new_toks  \\\n",
       "target                                    dataset_path            drafter                            temperature submission_id                           \n",
       "deepseek-ai/DeepSeek-R1-Distill-Llama-70B openai/openai_humaneval No Drafter (Autoregressive)        0           2025-02-04_01-05-29_4c55336     512.0   \n",
       "                                                                                                     1           2025-02-04_01-05-29_4c55336     512.0   \n",
       "                                                                  bigcode/tiny_starcoder_py          0           2025-02-04_01-05-29_4c55336     512.0   \n",
       "                                                                                                     1           2025-02-04_01-05-29_4c55336     512.0   \n",
       "                                                                  codellama/CodeLlama-7b-Instruct-hf 0           2025-02-04_01-05-29_4c55336     512.0   \n",
       "...                                                                                                                                                ...   \n",
       "mistralai/Mixtral-8x22B-Instruct-v0.1     tau/scrolls             No Drafter (Autoregressive)        1           2025-02-06_21-32-25_ab73cc7     237.2   \n",
       "                                                                  Qwen/Qwen2.5-0.5B-Instruct         0           2025-02-06_21-32-25_ab73cc7     188.3   \n",
       "                                                                                                     1           2025-02-06_21-32-25_ab73cc7     216.9   \n",
       "                                                                  double7/vicuna-68m                 0           2025-02-06_21-32-25_ab73cc7     191.6   \n",
       "                                                                                                     1           2025-02-06_21-32-25_ab73cc7     234.6   \n",
       "\n",
       "                                                                                                                                              ttft_ms  \\\n",
       "target                                    dataset_path            drafter                            temperature submission_id                          \n",
       "deepseek-ai/DeepSeek-R1-Distill-Llama-70B openai/openai_humaneval No Drafter (Autoregressive)        0           2025-02-04_01-05-29_4c55336    297.1   \n",
       "                                                                                                     1           2025-02-04_01-05-29_4c55336    244.0   \n",
       "                                                                  bigcode/tiny_starcoder_py          0           2025-02-04_01-05-29_4c55336    265.9   \n",
       "                                                                                                     1           2025-02-04_01-05-29_4c55336    258.7   \n",
       "                                                                  codellama/CodeLlama-7b-Instruct-hf 0           2025-02-04_01-05-29_4c55336    428.7   \n",
       "...                                                                                                                                               ...   \n",
       "mistralai/Mixtral-8x22B-Instruct-v0.1     tau/scrolls             No Drafter (Autoregressive)        1           2025-02-06_21-32-25_ab73cc7   1325.3   \n",
       "                                                                  Qwen/Qwen2.5-0.5B-Instruct         0           2025-02-06_21-32-25_ab73cc7   1395.3   \n",
       "                                                                                                     1           2025-02-06_21-32-25_ab73cc7   1365.3   \n",
       "                                                                  double7/vicuna-68m                 0           2025-02-06_21-32-25_ab73cc7   1336.1   \n",
       "                                                                                                     1           2025-02-06_21-32-25_ab73cc7   1322.4   \n",
       "\n",
       "                                                                                                                                              tpot_ms  \\\n",
       "target                                    dataset_path            drafter                            temperature submission_id                          \n",
       "deepseek-ai/DeepSeek-R1-Distill-Llama-70B openai/openai_humaneval No Drafter (Autoregressive)        0           2025-02-04_01-05-29_4c55336    122.6   \n",
       "                                                                                                     1           2025-02-04_01-05-29_4c55336    123.5   \n",
       "                                                                  bigcode/tiny_starcoder_py          0           2025-02-04_01-05-29_4c55336     84.6   \n",
       "                                                                                                     1           2025-02-04_01-05-29_4c55336     85.5   \n",
       "                                                                  codellama/CodeLlama-7b-Instruct-hf 0           2025-02-04_01-05-29_4c55336    101.5   \n",
       "...                                                                                                                                               ...   \n",
       "mistralai/Mixtral-8x22B-Instruct-v0.1     tau/scrolls             No Drafter (Autoregressive)        1           2025-02-06_21-32-25_ab73cc7    168.0   \n",
       "                                                                  Qwen/Qwen2.5-0.5B-Instruct         0           2025-02-06_21-32-25_ab73cc7     75.0   \n",
       "                                                                                                     1           2025-02-06_21-32-25_ab73cc7     98.5   \n",
       "                                                                  double7/vicuna-68m                 0           2025-02-06_21-32-25_ab73cc7    130.2   \n",
       "                                                                                                     1           2025-02-06_21-32-25_ab73cc7    136.4   \n",
       "\n",
       "                                                                                                                                              out_toks_per_sec  \n",
       "target                                    dataset_path            drafter                            temperature submission_id                                  \n",
       "deepseek-ai/DeepSeek-R1-Distill-Llama-70B openai/openai_humaneval No Drafter (Autoregressive)        0           2025-02-04_01-05-29_4c55336               8.2  \n",
       "                                                                                                     1           2025-02-04_01-05-29_4c55336               8.1  \n",
       "                                                                  bigcode/tiny_starcoder_py          0           2025-02-04_01-05-29_4c55336              11.8  \n",
       "                                                                                                     1           2025-02-04_01-05-29_4c55336              11.7  \n",
       "                                                                  codellama/CodeLlama-7b-Instruct-hf 0           2025-02-04_01-05-29_4c55336               9.6  \n",
       "...                                                                                                                                                        ...  \n",
       "mistralai/Mixtral-8x22B-Instruct-v0.1     tau/scrolls             No Drafter (Autoregressive)        1           2025-02-06_21-32-25_ab73cc7               5.9  \n",
       "                                                                  Qwen/Qwen2.5-0.5B-Instruct         0           2025-02-06_21-32-25_ab73cc7              11.0  \n",
       "                                                                                                     1           2025-02-06_21-32-25_ab73cc7               9.8  \n",
       "                                                                  double7/vicuna-68m                 0           2025-02-06_21-32-25_ab73cc7               7.5  \n",
       "                                                                                                     1           2025-02-06_21-32-25_ab73cc7               7.2  \n",
       "\n",
       "[333 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hf_bench.summarize_results import get_df_concat, get_df_summary_of_results\n",
    "\n",
    "\n",
    "dirpath = \"benchmark_results\"\n",
    "print(\"Concatenating all the results CSVs into one dataframe...\")\n",
    "df_concat: pd.DataFrame = get_df_concat(dirpath)\n",
    "df_concat.to_csv(\"results_all.csv\", index=False)\n",
    "\n",
    "print(\"Counting the number of unique example IDs for each experiment...\")\n",
    "df_summary: pd.DataFrame = get_df_summary_of_results(df_concat)\n",
    "# Round the values to 1 decimal place\n",
    "df_summary[\"new_toks\"] = df_summary[\"new_toks\"].round(1)\n",
    "df_summary[\"ttft_ms\"] = df_summary[\"ttft_ms\"].round(1)\n",
    "df_summary[\"tpot_ms\"] = df_summary[\"tpot_ms\"].round(1)\n",
    "df_summary[\"out_toks_per_sec\"] = df_summary[\"out_toks_per_sec\"].round(1)\n",
    "# Reorder the multi-index columns so that the `submission_id` column is the last one\n",
    "df_summary.reset_index(level=\"submission_id\", inplace=True)\n",
    "df_summary.set_index(\"submission_id\", append=True, inplace=True)\n",
    "df_summary\n",
    "\n",
    "# # Move the `submission_id` columns\n",
    "# df_summary = df_summary[\n",
    "#     [\n",
    "#         \"target\",\n",
    "#         \"dataset_path\",\n",
    "#         \"drafter\",\n",
    "#         \"temperature\",\n",
    "#         \"submission_id\",\n",
    "#         \"example_id_nunique\",\n",
    "#         \"new_toks\",\n",
    "#         \"ttft_ms\",\n",
    "#         \"tpot_ms\",\n",
    "#         \"out_toks_per_sec\",\n",
    "#     ]\n",
    "# ]\n",
    "# df_summary.sort_values(\n",
    "#     by=[\"target\", \"dataset_path\", \"drafter\", \"temperature\", \"submission_id\"],\n",
    "#     inplace=True,\n",
    "# )\n",
    "# df_summary.to_csv(\"results_summary.csv\", index=True)\n",
    "\n",
    "# print(f\"Stored both the concatenated dataframe and the summary in {dirpath}.\")\n",
    "# print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
